{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90bd3755-0c8f-4aa4-8480-0587a77e67a0",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each.\n",
    "ans =\n",
    "Linear Regression\n",
    "Also called simple regression, linear regression establishes the relationship between two variables. Linear regression is graphically depicted using a straight line with the slope defining how the change in one variable impacts a change in the other. The y-intercept of a linear regression relationship represents the value of one variable when the value of the other is 0.\n",
    "\n",
    "Multiple linear regression should be used when multiple independent variables determine the outcome of a single dependent variable. This is often the case when forecasting more complex relationships.\n",
    "\n",
    "Linear Regression vs. Multiple Regression Example\n",
    "Consider an analyst who wishes to establish a relationship between the daily change in a company's stock prices and the daily change in trading volume. Using linear regression, the analyst can attempt to determine the relationship between the two variables:\n",
    "\n",
    "Daily Change in Stock Price = (Coefficient)(Daily Change in Trading Volume) + (y-intercept)\n",
    "\n",
    "If the stock price increases $0.10 before any trades occur and increases $0.01 for every share sold, the linear regression outcome is:\n",
    "\n",
    "Daily Change in Stock Price = ($0.01)(Daily Change in Trading Volume) + $0.10\n",
    "\n",
    "However, the analyst realizes there are several other factors to consider including the company's P/E ratio, dividends, and prevailing inflation rate. The analyst can perform multiple regression to determine which—and how strongly—each of these variables impacts the stock price:\n",
    "\n",
    "Daily Change in Stock Price = (Coefficient)(Daily Change in Trading Volume) + (Coefficient)(Company's P/E Ratio) + (Coefficient)(Dividend) + (Coefficient)(Inflation Rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55ce072-4369-4ab0-82d6-968e74248f83",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?\n",
    "ans - \n",
    "There are primarily five assumptions of linear regression. They are:\n",
    "\n",
    "1.There is a linear relationship between the predictors (x) and the outcome (y)\n",
    "2.Predictors (x) are independent and observed with negligible error\n",
    "3.Residual Errors have a mean value of zero\n",
    "4.Residual Errors have constant variance\n",
    "5.Residual Errors are independent from each other and predictors (x)\n",
    "All the variables are normally distributed; to check, plot a histogram of the residuals. There are no outliers, (if there are outliers they need to be removed); to check use a test for detecting outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a09704-3d96-4d1c-9f21-97b9ffdd19a8",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario.\n",
    "ans \n",
    "The slope indicates the steepness of a line and the intercept indicates the location where it intersects an axis. The slope and the intercept define the linear relationship between two variables, and can be used to estimate an average rate of change.\n",
    "The slope is interpreted in algebra as rise over run. If, for example, the slope is 2, you can write this as 2/1 and say that as you move along the line, as the value of the X variable increases by 1, the value of the Y variable increases by 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530592de-4447-4385-b48e-9b1689b42d52",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "ANS - \n",
    "Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks. Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fab1f8-de95-47a4-84f6-bae0217c3381",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "ANS -\n",
    "Multiple regression is a broader class of regressions that encompasses linear and nonlinear regressions with multiple explanatory variables. Whereas linear regress only has one independent variable impacting the slope of the relationship, multiple regression incorporates multiple independent variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a58bf2-cfd5-4b91-b4b1-14bae7c19fc3",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?\n",
    "ANS - \n",
    "Multicollinearity occurs when independent variables in a regression model are correlated. This correlation is a problem because independent variables should be independent. If the degree of correlation between variables is high enough, it can cause problems when you fit the model and interpret the results.\n",
    "A very simple test known as the VIF test is used to assess multicollinearity in our regression model. The variance inflation factor (VIF) identifies the strength of correlation among the predictors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772eda93-0d6e-4080-b750-c183866951d7",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "ANS - \n",
    "A polynomial regression model is a machine learning model that can capture non-linear relationships between variables by fitting a non-linear regression line, which may not be possible with simple linear regression. It is used when linear regression models may not adequately capture the complexity of the relationship\n",
    "While linear regression is appropriate for modeling linear relationships between variables, polynomial regression is used for modeling non-linear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78509d99-cd55-4a3e-8192-995ec5aef262",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?\n",
    "ANS -\n",
    "1.Polynomial provides the best approximation of the relationship between the dependent and independent variable. * Broad range of function can be fit under it. It basically fits a wide range of curvature.\n",
    "2.Polynomial models have a simple form.\n",
    "3.Polynomial models have moderate flexibility of shapes.\n",
    "Disadvantages:\n",
    "1.One or two outliers in the data might have a significant impact on the nonlinear analysis' outcomes. These are overly reliant on outliers. Furthermore, there are fewer model validation methods for detecting outliers in nonlinear regression than there are for linear regression.\n",
    "2. main challenges of polynomial regression is overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
